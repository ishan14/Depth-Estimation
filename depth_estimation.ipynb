{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "depth_estimation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD7AJTApvJSo"
      },
      "source": [
        "import h5py\r\n",
        "from PIL import Image\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, LeakyReLU, Concatenate, Dropout, Dense, Flatten\r\n",
        "from keras.activations import sigmoid\r\n",
        "import time\r\n",
        "from IPython import display\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "from zipfile import ZipFile\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "SPkQ0RDuisWM",
        "outputId": "ab210deb-cdad-4b7c-b5aa-93de775ce106"
      },
      "source": [
        "def extract_zip(input_zip):\r\n",
        "    input_zip=ZipFile(input_zip)\r\n",
        "    return {name: input_zip.read(name) for name in input_zip.namelist()}\r\n",
        "\r\n",
        "def parse_function(filename, label):\r\n",
        "    image_string = tf.io.read_file(filename)\r\n",
        "    label_string = tf.io.read_file(label)\r\n",
        "\r\n",
        "    #Don't use tf.image.decode_image, or the output shape will be undefined\r\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\r\n",
        "    label = tf.image.decode_jpeg(label_string, channels=1)\r\n",
        "\r\n",
        "    #This will convert to float values in [0, 1]\r\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\r\n",
        "    label = tf.image.convert_image_dtype(label, tf.float32)\r\n",
        "\r\n",
        "    image = tf.image.resize(image, [128, 416], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
        "    label = tf.image.resize(label, [128, 416], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
        "\r\n",
        "    image = (image / 127.5) - 1\r\n",
        "    label = (label / 127.5) - 1\r\n",
        "\r\n",
        "    return image, label\r\n",
        "\r\n",
        "'''\r\n",
        "def train_preprocess(image, label):\r\n",
        "    image = tf.image.random_flip_left_right(image)\r\n",
        "\r\n",
        "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\r\n",
        "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\r\n",
        "\r\n",
        "    #Make sure the image is still in [0, 1]\r\n",
        "    image = tf.clip_by_value(image, 0.0, 1.0)\r\n",
        "\r\n",
        "    return image, label\r\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIM4JbaFiuQX"
      },
      "source": [
        "data = extract_zip('nyu_data.zip')\r\n",
        "nyu2_train = list((row.split(',') for row in (data['data/nyu2_train.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))\r\n",
        "nyu2_test = list((row.split(',') for row in (data['data/nyu2_test.csv']).decode(\"utf-8\").split('\\n') if len(row) > 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_JxLaRgiyUG"
      },
      "source": [
        "nyu2_train_image = []\r\n",
        "nyu2_train_label = []\r\n",
        "for e in range(len(nyu2_train)):\r\n",
        "  nyu2_train_image.append(nyu2_train[e][0])\r\n",
        "  nyu2_train_label.append(nyu2_train[e][1])\r\n",
        "\r\n",
        "nyu2_test_image = []\r\n",
        "nyu2_test_label = []\r\n",
        "for e in range(len(nyu2_test)):\r\n",
        "  nyu2_test_image.append(nyu2_test[e][0])\r\n",
        "  nyu2_test_label.append(nyu2_test[e][1])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frrH0q2ii55C"
      },
      "source": [
        "data = tf.data.Dataset.from_tensor_slices((nyu2_train_image, nyu2_train_label))\r\n",
        "data = data.map(parse_function, num_parallel_calls=tf.data.AUTOTUNE)\r\n",
        "data = data.shuffle(1024)\r\n",
        "train_dataset = data.take(50000)\r\n",
        "test_dataset = data.skip(50000)\r\n",
        "train_dataset = train_dataset.batch(32)\r\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9B46Km_yNvC"
      },
      "source": [
        "def downsample(filters, size, stride, apply_batchnorm = True):\r\n",
        "\r\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "  result = keras.Sequential()\r\n",
        "  if filters == 1:\r\n",
        "      result.add(Conv2D(filters = filters, kernel_size = size,strides = stride, padding = 'same',\r\n",
        "                        activation = 'sigmoid', kernel_initializer = initializer, use_bias = False))\r\n",
        "  else:\r\n",
        "    result.add(Conv2D(filters = filters, kernel_size = size,strides = stride, padding = 'same', kernel_initializer = initializer, use_bias = False))\r\n",
        "\r\n",
        "  if apply_batchnorm:\r\n",
        "    result.add(BatchNormalization())\r\n",
        "  \r\n",
        "  result.add(LeakyReLU())\r\n",
        "  \r\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4cHNI_t0Vuq"
      },
      "source": [
        "def upsample(filters, size, stride, apply_dropout = True):\r\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "  result = keras.Sequential()\r\n",
        "  result.add(Conv2DTranspose(filters = filters, kernel_size = size, strides = stride, padding = 'same', kernel_initializer = initializer, use_bias = False))\r\n",
        "  result.add(BatchNormalization())\r\n",
        "\r\n",
        "  if apply_dropout:\r\n",
        "    result.add(Dropout(0.5))\r\n",
        "  \r\n",
        "  result.add(LeakyReLU())\r\n",
        "  return result\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vf0-ZDG5WGq"
      },
      "source": [
        "def resize_like(inputs, ref):\r\n",
        "    iH, iW = inputs.get_shape()[1], inputs.get_shape()[2]\r\n",
        "    rH, rW = ref.get_shape()[1], ref.get_shape()[2]\r\n",
        "\r\n",
        "    if iH == rH and iW == rW:\r\n",
        "        return inputs\r\n",
        "    return tf.image.resize(inputs, [rH, rW], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
        "\r\n",
        "DISP_SCALING = 10\r\n",
        "MIN_DISP = 0.01\r\n",
        "H = 128\r\n",
        "W = 416"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDUq_O3ytwI5"
      },
      "source": [
        "def Generator():\r\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 416, 3])\r\n",
        "\r\n",
        "  cnv = inputs\r\n",
        "  cnv1 = downsample(32, 7, 2, apply_batchnorm = False)(cnv)\r\n",
        "  cnv1b = downsample(32, 7, 1)(cnv1)\r\n",
        "  cnv2 = downsample(64, 5, 2, apply_batchnorm = False)(cnv1b)\r\n",
        "  cnv2b = downsample(64, 5, 1)(cnv2)\r\n",
        "  cnv3 = downsample(128, 3, 2, apply_batchnorm = False)(cnv2b)\r\n",
        "  cnv3b = downsample(128, 3, 1)(cnv3)\r\n",
        "  cnv4 = downsample(256, 3, 2, apply_batchnorm = False)(cnv3b)\r\n",
        "  cnv4b = downsample(256, 3, 1)(cnv4)\r\n",
        "  cnv5 = downsample(512, 3, 2, apply_batchnorm = False)(cnv4b)\r\n",
        "  cnv5b = downsample(512, 3, 1)(cnv5)\r\n",
        "  cnv6 = downsample(512, 3, 2, apply_batchnorm = False)(cnv5b)\r\n",
        "  cnv6b = downsample(512, 3, 1)(cnv6)\r\n",
        "  cnv7 = downsample(512, 3, 2, apply_batchnorm = False)(cnv6b)\r\n",
        "  cnv7b = downsample(512, 3, 1)(cnv7)\r\n",
        "\r\n",
        "  upcnv7 = upsample(512, 3, 2)(cnv7b)\r\n",
        "  upcnv7 = resize_like(upcnv7, cnv6b)\r\n",
        "  i7_in = Concatenate()([upcnv7, cnv6b])      ### if not working use tf.concat([upcnv7, cnv6b], axis = 3)\r\n",
        "  icnv7 = downsample(512, 3, 1)(i7_in)\r\n",
        "\r\n",
        "  upcnv6 = upsample(512, 3, 2)(icnv7)\r\n",
        "  upcnv6 = resize_like(upcnv6, cnv5b)\r\n",
        "  i6_in = Concatenate()([upcnv6, cnv5b])      \r\n",
        "  icnv6 = downsample(512, 3, 1)(i6_in)\r\n",
        "\r\n",
        "  upcnv5 = upsample(256, 3, 2)(icnv6)\r\n",
        "  upcnv5 = resize_like(upcnv5, cnv4b)\r\n",
        "  i5_in = Concatenate()([upcnv5, cnv4b])      \r\n",
        "  icnv5 = downsample(256, 3, 1)(i5_in)\r\n",
        "\r\n",
        "  upcnv4 = upsample(128, 3, 2)(icnv5)\r\n",
        "  i4_in = Concatenate()([upcnv4, cnv3b])\r\n",
        "  icnv4 = downsample(128, 3, 1)(i4_in)      \r\n",
        "  #disp4 = DISP_SCALING * downsample(1, 3, 1)(i4_in) + MIN_DISP\r\n",
        "  disp4 = downsample(1,3,1)(i4_in)\r\n",
        "  disp4_up = tf.image.resize(disp4, [np.int(H/4), np.int(W/4)], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
        "\r\n",
        "  upcnv3 = upsample(64, 3, 2)(icnv4)\r\n",
        "  i3_in = Concatenate()([upcnv3, cnv2b, disp4_up])      \r\n",
        "  icnv3 = downsample(64, 3, 1)(i3_in)\r\n",
        "  disp3 = DISP_SCALING * downsample(1, 3, 1)(i3_in) + MIN_DISP\r\n",
        "  disp3_up = tf.image.resize(disp3, [np.int(H/2), np.int(W/2)], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
        "\r\n",
        "  upcnv2 = upsample(32, 3, 2)(icnv3)\r\n",
        "  i2_in = Concatenate()([upcnv2, cnv1b, disp3_up])      \r\n",
        "  icnv2 = downsample(32, 3, 1)(i2_in)\r\n",
        "  disp2 = DISP_SCALING * downsample(1, 3, 1)(i2_in) + MIN_DISP\r\n",
        "  disp2_up = tf.image.resize(disp2, [np.int(H), np.int(W)], method = tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
        "\r\n",
        "  upcnv1 = upsample(16, 3, 2)(icnv2)\r\n",
        "  i1_in = Concatenate()([upcnv1, disp2_up])      \r\n",
        "  icnv1 = downsample(16, 3, 1)(i1_in)\r\n",
        "  disp1 = DISP_SCALING * downsample(1, 3, 1)(i1_in) + MIN_DISP\r\n",
        "\r\n",
        "  #pred_disp = [disp1, disp2, disp3, disp4]\r\n",
        "  \r\n",
        "  #pred_depth = [1./d for d in pred_disp]\r\n",
        "  return tf.keras.Model(inputs = inputs, outputs = disp1 )\r\n",
        "  #return disp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61qtAVYnDwcf"
      },
      "source": [
        "LAMBDA = 100\r\n",
        "def generator_loss(disc_generated_output, gen_output, target):\r\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\r\n",
        "\r\n",
        "  # mean absolute error\r\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\r\n",
        "\r\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\r\n",
        "\r\n",
        "  return total_gen_loss, gan_loss, l1_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9mDxe7pI2MB"
      },
      "source": [
        "def Discriminator():\r\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "\r\n",
        "  inp = keras.layers.Input(shape = [128, 416, 3], name = 'input_image')\r\n",
        "  tar = keras.layers.Input(shape = [128, 416, 1], name = 'target_image')\r\n",
        "\r\n",
        "  x = Concatenate()([inp, tar])\r\n",
        "\r\n",
        "  down1 = downsample(32, 5, 2)(x)\r\n",
        "  down2 = downsample(64, 3, 2)(down1)\r\n",
        "  down3 = downsample(64, 3, 2)(down2)\r\n",
        "  down4 = downsample(128, 3, 2)(down3)\r\n",
        "  down5 = downsample(128, 3, 2)(down4)\r\n",
        "  down6 = downsample(256, 3, 2)(down5)\r\n",
        "  down7 = downsample(256, 3, 2)(down6)\r\n",
        "  down8 = downsample(512, 3, 2)(down7)\r\n",
        "\r\n",
        "  flat = Flatten()(down8)\r\n",
        "  dense1 = Dense(512, activation = LeakyReLU())(flat)\r\n",
        "  dense2 = Dense(256, activation = LeakyReLU())(dense1)\r\n",
        "  dense3 = Dense(128, activation = LeakyReLU())(dense2)\r\n",
        "  pred_head = Dense(1, activation = 'sigmoid')(dense3)\r\n",
        "\r\n",
        "  return tf.keras.Model(inputs = [inp, tar], outputs = pred_head)\r\n",
        "  #return pred_head\r\n",
        "  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MYg8tMNUDdc"
      },
      "source": [
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PENzaWPVZcH"
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\r\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\r\n",
        "\r\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\r\n",
        "\r\n",
        "  total_disc_loss = real_loss + generated_loss\r\n",
        "\r\n",
        "  return total_disc_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAsCT8hSXtdO"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\r\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49hXWhg6XyEZ"
      },
      "source": [
        "def generate_images(model, test_input, tar):\r\n",
        "  prediction = model(test_input, training=True)\r\n",
        "  plt.figure(figsize=(15,15))\r\n",
        "\r\n",
        "  display_list = [test_input[0], tar[0].numpy().squeeze(), prediction[0].numpy().squeeze()]\r\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\r\n",
        "\r\n",
        "  for i in range(3):\r\n",
        "    plt.subplot(1, 3, i+1)\r\n",
        "    plt.title(title[i])\r\n",
        "    # getting the pixel values between [0, 1] to plot it.\r\n",
        "    plt.imshow(display_list[i] * 0.5 + 0.5)\r\n",
        "    plt.axis('off')\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JLdpCUjah3L"
      },
      "source": [
        "generator = Generator()\r\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG4NDBIF9WrI"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\r\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\r\n",
        "                                 generator=generator,\r\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTgFjSiQeWkV",
        "outputId": "e7b4a129-f7b3-4c42-ad2f-009b2690f516"
      },
      "source": [
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ouk2ItDWX4ec"
      },
      "source": [
        "for example_input, example_target in test_dataset.take(1):\r\n",
        "  generate_images(generator, example_input, example_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wM2kJlkDblGG"
      },
      "source": [
        "import datetime\r\n",
        "log_dir=\"logs/\"\r\n",
        "\r\n",
        "summary_writer = tf.summary.create_file_writer(\r\n",
        "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdBlbZUbcVty"
      },
      "source": [
        "#@tf.function\r\n",
        "def train_step(input_image, target, epoch):\r\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n",
        "    gen_output = generator(input_image, training=True)\r\n",
        "\r\n",
        "    disc_real_output = discriminator([input_image, target], training=True)\r\n",
        "    disc_generated_output = discriminator([input_image, gen_output], training=True)\r\n",
        "\r\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\r\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\r\n",
        "\r\n",
        "  generator_gradients = gen_tape.gradient(gen_total_loss,\r\n",
        "                                          generator.trainable_variables)\r\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss,\r\n",
        "                                               discriminator.trainable_variables)\r\n",
        "\r\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients,\r\n",
        "                                          generator.trainable_variables))\r\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\r\n",
        "                                              discriminator.trainable_variables))\r\n",
        "  print(f\"Epoch: {epoch} | gen_loss: {gen_total_loss} | disc_loss: {disc_loss} \")\r\n",
        "  with summary_writer.as_default():\r\n",
        "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\r\n",
        "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\r\n",
        "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\r\n",
        "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqUm5t41caHS"
      },
      "source": [
        "def fit(train_ds, epochs, test_ds):\r\n",
        "  for epoch in range(epochs):\r\n",
        "    start = time.time()\r\n",
        "\r\n",
        "    display.clear_output(wait=True)\r\n",
        "    '''\r\n",
        "    for example_input, example_target in test_ds.take(1):\r\n",
        "      generate_images(generator, example_input, example_target)\r\n",
        "    print(\"Epoch: \", epoch)\r\n",
        "    '''\r\n",
        "    # Train\r\n",
        "    for n, (input_image, target) in train_ds.enumerate():\r\n",
        "      print('.', end='')\r\n",
        "      if (n+1) % 100 == 0:\r\n",
        "        print()\r\n",
        "      train_step(input_image, target, epoch)\r\n",
        "    print()\r\n",
        "\r\n",
        "    # saving (checkpoint) the model every 20 epochs\r\n",
        "    if (epoch + 1) % 20 == 0:\r\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "\r\n",
        "    print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\r\n",
        "                                                        time.time()-start))\r\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpvAdsC6blKE"
      },
      "source": [
        "EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "USI78UUscdcM",
        "outputId": "b344fce2-865c-4d62-9e28-0b851b8344df"
      },
      "source": [
        "fit(train_dataset, EPOCHS, test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}